{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtdE02UcwYen",
    "outputId": "f9fc774f-4f47-423b-b15a-10f7707a27d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting telebot\n",
      "  Downloading telebot-0.0.5-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pyTelegramBotAPI (from telebot)\n",
      "  Downloading pytelegrambotapi-4.28.0-py3-none-any.whl.metadata (48 kB)\n",
      "\u001B[?25l     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m0.0/48.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m48.3/48.3 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from telebot) (2.32.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from pyTelegramBotAPI->telebot) (3.12.15)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from pyTelegramBotAPI->telebot) (8.4.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from pyTelegramBotAPI->telebot) (0.45.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (2025.8.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->pyTelegramBotAPI->telebot) (1.20.1)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->pyTelegramBotAPI->telebot) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest->pyTelegramBotAPI->telebot) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->pyTelegramBotAPI->telebot) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->pyTelegramBotAPI->telebot) (2.19.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->pyTelegramBotAPI->telebot) (4.14.1)\n",
      "Downloading telebot-0.0.5-py3-none-any.whl (4.8 kB)\n",
      "Downloading pytelegrambotapi-4.28.0-py3-none-any.whl (290 kB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m290.7/290.7 kB\u001B[0m \u001B[31m22.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pyTelegramBotAPI, telebot\n",
      "Successfully installed pyTelegramBotAPI-4.28.0 telebot-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZVk3NkAwYep",
    "outputId": "e87de226-7fda-4ccb-802f-af7283a465dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m61.3/61.3 MB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaRBFZjvwYeq"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 498,
     "referenced_widgets": [
      "740f2e37273f435f878ee90e1fcfe824",
      "af472670f5a34d8bbb5b2d50e907265a",
      "a94e23062eb94db0ae63cdebd565c01e",
      "fa0354fbd40d437aa6143f3160a2a81b",
      "2875e5a3415b40a5be13a10980197014",
      "2ba5acc6203b4837939cd057c134b1ae",
      "3e2d5d64f41747f1aa9aa7c17cedd036",
      "79a0274d004d4bf4b294180abc5eab71",
      "08c0561145f34532a8098477db20ea9d",
      "50c2da67612c4713b41daee4a2c99997",
      "d5cb892e87aa41b2a35a381ba22ea7c8",
      "f9596fd79dfb4176bb842ab9419f9cdb",
      "7435c20996024dd6837909738bc09f86",
      "9f7b4987055d463aa14d52427afa1033",
      "94bf6abf612841de8f4184c59db3baf4",
      "a39a2df44d3643fb8608693360640337",
      "30f625ce86084a5a8d4f4993d05a8b41",
      "b5c5621938784b5d842fb77710d1bc88",
      "febf074053c84e529eed82823d773fe0",
      "a53c0745975547cd961feabda40463a2",
      "65252e9a233248efbec797a6e524ccc1",
      "62925cec5795400a8851a77ef2fd82e0",
      "3310d406a41b49c7ab42bdb49e654af1",
      "7a870ae185e74fa2a70540f2b8d4381f",
      "0783a1f503904dc5a146a22b63747e90",
      "45a0d16fef2f488b9e979a43885d1317",
      "bb0092b8b60f4f97afb8ef75ff95d6c4",
      "e09862cdd81f49d79545b536f19f6be4",
      "1462390b8fb74489989f74946a1fd427",
      "fdbee2a2728646b9b6e043b1811fc0ee",
      "5bd890a01a8e4f718b873a0e5289df05",
      "e7d8b63044ae424eb445e28bc09c9636",
      "334ea9de3141448ab8d2592ee4c0bb09",
      "a49f28b2d13f4993a0eee90610347275",
      "666b8e818f2842d98acc546f32443746",
      "6fb1f1150b4a4871812b2d8ac6d7faa2",
      "a64822ae88b74f469f07f0d28a638f09",
      "56caa5437287472db02d022d4275a2ff",
      "03fac627a90341bab5aa123fdfabe793",
      "fc59f19c2a3a42b1ab1a28618b3161fe",
      "a64f6e1d7bd14ff7a201a2633991b406",
      "af5f88e7b81f41edad26f8c41ead62de",
      "3a8e89927ec44b8d988a4d19105a0860",
      "f413f540eb3e41e2b9975df25c3da43f",
      "f2808c00ba53441d814e5d78f2f12150",
      "a7391a9ba81f4d60964332d022bcc276",
      "282322d8e5274e11acb0d7fd4fc61e41",
      "bee98a8e18e144bd80bb3de5bafbd88e",
      "8e8916f1bbd14a0785d2ae0262dea397",
      "dd8a2506b53c4d1fbfa64d0ee60bf202",
      "7c65f4f1b8d14dcd99b3b95876f7ad56",
      "aa18e8cae82c4a179340ef998e8cf1ed",
      "7b04d8072631425bab99d031b53f5c77",
      "5df86cc6123a4742bbc87c1bb3580dc7",
      "e4aa959a1db147feaa063189b8768759",
      "007ad04f7d0646e4b9467b52b9d26178",
      "89c483a3949543ee992721083deb2018",
      "ab6edc1e8098414a8d49d7ec3c112d36",
      "112cc46afdab4a629bdfbef03df7b624",
      "c3da4abf6e7f4c6aaa8539bd7fc64682",
      "79cb04ebf66a41faacb18355434ce32a",
      "af74e9b9c3ec49a5a17591057fd61e59",
      "d4f69f7be5ef4ee7a7a202650596c121",
      "a10c8bb29ddd49778b59f0b2e36da59d",
      "fb7633160a3943ae86f05bfd17569d3d",
      "29b754216bbc48ba872d8e2b75304630",
      "a0d14ae3d1ff455fa51668982bee6b77",
      "b50de1768a2148d1b7ee21cd52a131ff",
      "ad4df69a4ecb4e79bb70899165248438",
      "5f0a6459caec44fdb2d16dab5a71f82e",
      "77aadcacdcde47f09a3f571880f4bc34",
      "1f3bf197f8d9425c914a6273cd184303",
      "5a440aceb7f94badbc5bc237345431f0",
      "0a962de08f7f4e1a82d5f49540edfbb4",
      "8db87c48ab7d4866a7f91b208b1be8d1",
      "c46048890b294f2c9c7ab40117d7a059",
      "498d79c8eb6e44b0a55443eb1db37d3c",
      "1e86615a79ab45eca578179b637dd9f1",
      "efa7ea587369429e85093d302d93fb3c",
      "87ae34680b064062b9a2d9c2405184db",
      "b520a700014943d28c27cc859c4d7f89",
      "fd81fd6ed1f04aa98ca73d71c42a9416",
      "ed72d6fc3f29476eaa91065e8bf399cf",
      "8fc199119ad6439d86b3f0808ee2e314",
      "3f7467992f50484fa5a3fb520a1af05e",
      "f88e34728f0c46339c5cd59e8c5088b1",
      "3bf2990cfc3d4cf3832e2baa0acdf7a5",
      "600fee1cc89b4698b79bb8d8652d2502",
      "5e30297bacd746c6aaf8e45a1844ac1a",
      "8f75c9afb20f48d2b35f0222b145f739",
      "8722221636d74cf798783ac1068f7698",
      "9e52f91ebd584a93a0693eb0e9e27360",
      "0715c9039db54b15830e60c964a84eb9",
      "a50f610d57624d65ad7855ccfa5d81b5",
      "9c5577115a884e6d98938cc1ac0daadc",
      "fe3c468c3fe04fe88f4ed91669f3a8d6",
      "1057503df3d040f8a394767255e92c02",
      "f3be8365f84246c5adee9e794d75ea94",
      "03a8034bb495437ab42a598c92c7fa20",
      "ad56f2c3790b43ceab019fef4a19045b",
      "448d8cd26baa4e40b94fafcaf1328745",
      "6bc383342248426fa62dbc33f2ce2191",
      "a9c15934d9f74faf83ff50255a695e9e",
      "09ca9ba6674a4b7da17c99ff68329fcc",
      "7633b269ec904104a7b33571f2ea9c3b",
      "9e19b22c1ea045f69f6ca928ca354ae0",
      "1d1392fea3f64db8a90926a954afe613",
      "e599812d0132405eaac0d8090800924c",
      "f09a88203755473883160b8edaab9c8c",
      "3dddf1ef8d854d05ac28265093c6c6cf",
      "e3707c5d848c4f369e65a4459a85ecad",
      "9f81480e889541a58ea899569216ee85",
      "96820f133d8842ccb5f8281c97572b02",
      "bec926644c5d4e65bf002a361e94bcd6",
      "203a61efefea4a308aec0fb02c9b0e95",
      "b25c9b105f554a6eb349136dbfd40100",
      "b3b0c9ef86cf4470bf59e4ec50ffc040",
      "94350cfe2b6c44aeb5a14119e0f91f27",
      "a7b678ab3bb44a9d811846c1ff0c3147",
      "22c25ac09e5246808d84cf9dade7bcf8",
      "3738e6723dfc434bbdfdd4de7af522a6",
      "79f3a3c7604f4f34a71f93f4dc2a0593"
     ]
    },
    "id": "vXl8N9dCwYeq",
    "outputId": "accb42bc-545b-429a-bb70-443695a79e55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,                         # 8-bit quant\n",
    "    llm_int8_enable_fp32_cpu_offload=True      # ‚úÖ allow CPU offload safely\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",                         # spread across GPU+CPU\n",
    "    low_cpu_mem_usage=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wQHPZnqRwYeq",
    "outputId": "2bff9dec-fbf0-43db-efad-0e8b1617caac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "from telebot import types\n",
    "\n",
    "# def generate_text(prompt: str, max_len: int = 128) -> str:\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "#     inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "#     outputs = model.generate(**inputs, max_length=max_len)\n",
    "#     return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ================== BOT SETUP ==================\n",
    "bot_token = \"8490280338:AAGRcnOmW3QxJB14vkGxMDKrkv2ikna8aug\"\n",
    "bot = telebot.TeleBot(bot_token)\n",
    "\n",
    "# Store user states\n",
    "user_states = {}\n",
    "\n",
    "# ================== AI HELPERS ==================\n",
    "def fix_grammar(sentence: str) -> str:\n",
    "    prompt = f\"You're an expert English tutor. Fix grammar mistakes in this sentence:\\n\\n{sentence}\\n\\nCorrected version:\"\n",
    "    return generate_text(prompt)\n",
    "\n",
    "def generate_text(prompt):\n",
    "    chat_prompt = f\"[INST] {prompt.strip()} [/INST]\"\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=300,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Zero-shot: Find resources for a topic\n",
    "def test_english(level: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are an English teacher. Create MCQs (Multiple Choice Questions) for grammar and vocabulary.\n",
    "    Each question should have 4 options and the correct answer should be clearly marked.\n",
    "\n",
    "    Example 1 (Grammar):\n",
    "    Q: Choose the correct sentence.\n",
    "    a) He go to school every day.\n",
    "    b) He goes to school every day. ‚úÖ\n",
    "    c) He going to school every day.\n",
    "    d) He gone to school every day.\n",
    "\n",
    "    Example 2 (Vocabulary):\n",
    "    Q: What is the synonym of 'happy'?\n",
    "    a) Sad\n",
    "    b) Angry\n",
    "    c) Joyful ‚úÖ\n",
    "    d) Lonely\n",
    "\n",
    "    Now generate 3 new questions (mix grammar and vocabulary).\n",
    "    for english level: {level}\n",
    "    \"\"\"\n",
    "    return generate_text(prompt)\n",
    "\n",
    "def suggest_resources(text: str) -> str:\n",
    "    prompt = f\"\"\"You are an English teacher. Provide study resources for improving\n",
    "    grammar and vocabulary. Include practice tips and example sentences about topic: {text}.\"\"\"\n",
    "    return generate_text(prompt)\n",
    "\n",
    "# ================== TELEGRAM FLOWS ==================\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start_menu(message):\n",
    "    chat_id = message.chat.id\n",
    "    markup = types.InlineKeyboardMarkup()\n",
    "    btn1 = types.InlineKeyboardButton(\"üõ† Fix Grammar\", callback_data=\"fix\")\n",
    "    btn2 = types.InlineKeyboardButton(\"‚úÖ Test Your English\", callback_data=\"test\")\n",
    "    btn3 = types.InlineKeyboardButton(\"üìö Resources\", callback_data=\"resources\")\n",
    "    markup.add(btn1, btn2, btn3)\n",
    "    bot.send_message(chat_id, \"Please select an option:\", reply_markup=markup)\n",
    "\n",
    "# --- Levels Menu ---\n",
    "def english_levels(message):\n",
    "    chat_id = message.chat.id\n",
    "    markup = types.InlineKeyboardMarkup()\n",
    "    for level in [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]:\n",
    "        markup.add(types.InlineKeyboardButton(level, callback_data=level))\n",
    "    bot.send_message(chat_id, \"Please select a level:\", reply_markup=markup)\n",
    "\n",
    "# --- Handle Option Selection ---\n",
    "@bot.callback_query_handler(func=lambda call: True)\n",
    "def handle_option(call):\n",
    "    chat_id = call.message.chat.id\n",
    "\n",
    "    if call.data == \"fix\":\n",
    "        user_states[chat_id] = \"fix\"\n",
    "        bot.send_message(chat_id, \"‚úçÔ∏è Send me the sentence you want me to fix.\")\n",
    "\n",
    "    elif call.data == \"test\":\n",
    "        user_states[chat_id] = \"test\"\n",
    "        english_levels(call.message)\n",
    "\n",
    "    elif call.data == \"resources\":\n",
    "        user_states[chat_id] = \"resources\"\n",
    "        bot.send_message(chat_id, \"‚úçÔ∏è Send me a text, and I'll suggest resources.\")\n",
    "\n",
    "    elif call.data in [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]:\n",
    "        level = call.data\n",
    "        user_states[chat_id] = f\"test_{level}\"\n",
    "        bot.send_message(chat_id, f\"üìñ Level {level} selected. Generating your English test...\")\n",
    "        test = test_english(level=level)\n",
    "        bot.send_message(chat_id, f\"üìù Your English Test:\\n\\n{test}\")\n",
    "\n",
    "# --- Handle Text Input After Choosing ---\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_text(message):\n",
    "    chat_id = message.chat.id\n",
    "    text = message.text\n",
    "\n",
    "    if chat_id not in user_states:\n",
    "        bot.send_message(chat_id, \"‚ö†Ô∏è Please type /start and choose an option first.\")\n",
    "        return\n",
    "\n",
    "    state = user_states[chat_id]\n",
    "\n",
    "    if state == \"fix\":\n",
    "        fixed = fix_grammar(text)\n",
    "        bot.send_message(chat_id, f\"üîß Fixed Sentence:\\n{fixed}\")\n",
    "\n",
    "    elif state.startswith(\"test_\"):\n",
    "        bot.send_message(chat_id, \"‚úÖ Please answer the test by sending option letters (A, B, C...).\")\n",
    "\n",
    "    elif state == \"resources\":\n",
    "        recs = suggest_resources(text)\n",
    "        bot.send_message(chat_id, f\"üìö Recommended Resources:\\n{recs}\")\n",
    "\n",
    "    user_states.pop(chat_id, None)\n",
    "\n",
    "# ================== RUN BOT ==================\n",
    "bot.infinity_polling()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
